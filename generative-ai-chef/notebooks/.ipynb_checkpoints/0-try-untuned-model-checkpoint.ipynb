{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "026280cd",
   "metadata": {},
   "source": [
    "### T5-Base\n",
    "\n",
    "Let's try the model first directly without tunning it to see what results we would get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8b0e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the T5 without our fine tuning\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(\"t5-base\", model_max_len=512)\n",
    "\n",
    "# gpt2_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "# gpt2_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "t5_generator = pipeline(model=t5_model, tokenizer=t5_tokenizer, task=\"text2text-generation\")\n",
    "# gpt2_generator = pipeline(model=gpt2_model, tokenizer=gpt2_tokenizer, task=\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a65c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'cooking oats, brown sugar, salad oil, eggs, salt, almond extract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6381bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe: cooking oats, brown sugar, brown sugar, brown sugar, eggs, salt, almond extract, salt, almond extract, almond extract, salt, almond extract, almond extract, salt, almond extract, almond extract, salt, almond extract, almond extract, salt, almond extract, almond extract, salt, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond\n"
     ]
    }
   ],
   "source": [
    "tokenizer_kwargs = {\n",
    "    'max_length':512\n",
    "}\n",
    "\n",
    "response = t5_generator(f\"generate recipe: {prompt}\", **tokenizer_kwargs)\n",
    "\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4e780e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipe: cooking oats, brown sugar, brown sugar, brown sugar, eggs, salt, almond extract, salt, almond extract, almond extract, salt, almond extract, almond extract, salt, almond extract, almond extract, salt, almond extract, almond extract, salt, almond extract, almond extract, salt, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond extract, almond\n"
     ]
    }
   ],
   "source": [
    "# response = t5_generator(f\"generate recipe: {prompt}\", **tokenizer_kwargs)\n",
    "outputs = gpt2_generator(f\"generate recipe: {prompt}\", num_return_sequences=4, return_full_text=False)\n",
    "\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6aac46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recipe: cooking', 'recipe:,', 'recipe: baking', 'recipe: o']\n"
     ]
    }
   ],
   "source": [
    "t5_tokenizer.pad_token_id = t5_tokenizer.eos_token_id\n",
    "\n",
    "prompt = 'cooking oats, brown sugar, salad oil, eggs, salt, almond extract'\n",
    "\n",
    "input_text = f\"generate recipe: {prompt}\"\n",
    "inputs = t5_tokenizer([input_text], return_tensors=\"pt\")\n",
    "\n",
    "output_ids = t5_model.generate(**inputs, max_new_tokens=5, num_beams=4, num_return_sequences=4, return_dict_in_generate=True,output_scores=True)\n",
    "output_text = t5_tokenizer.batch_decode(output_ids[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20f2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch110_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch110_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
